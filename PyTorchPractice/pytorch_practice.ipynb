{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensor的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1832, -0.8339, -0.4587,  0.8328],\n",
       "         [-0.3546,  1.2222,  1.1350,  1.4671],\n",
       "         [-1.9389, -1.1653, -0.1825, -1.2143]],\n",
       "\n",
       "        [[-1.4831,  1.0244, -0.5144,  0.3595],\n",
       "         [ 0.5914, -2.3901, -0.7608, -0.4785],\n",
       "         [-0.3594,  1.0850, -0.7563, -2.0344]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x = torch.randn((2, 3, 4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  8.],\n",
       "        [10., 12.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "y = torch.Tensor([[5, 6], [7, 8]])\n",
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((2, 4, 6))\n",
    "# x = x.view(-1)\n",
    "x = x.view(6, -1) # 等价于 x = x.view(6, 8)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 计算图和自动微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn.functional import relu, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将Tensor变为Variable\n",
    "x = Variable(torch.Tensor([1,2,3]), requires_grad=True)\n",
    "# 将Variable变为Tensor\n",
    "# x = x.data\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 6.], grad_fn=<AddBackward0>)\n",
      "tensor(10., grad_fn=<SumBackward0>)\n",
      "tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1, 2]), requires_grad=True)\n",
    "y = Variable(torch.Tensor([3, 4]), requires_grad=True)\n",
    "z = x + y\n",
    "print(z)\n",
    "s = z.sum()\n",
    "print(s)\n",
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Size of x:  torch.Size([5, 3])\n",
      "tensor([[-0.2406,  0.6009, -0.3527,  0.5031, -0.1083],\n",
      "        [-0.2406,  0.6009, -0.3527,  0.5031, -0.1083],\n",
      "        [-0.2406,  0.6009, -0.3527,  0.5031, -0.1083],\n",
      "        [-0.2406,  0.6009, -0.3527,  0.5031, -0.1083],\n",
      "        [-0.2406,  0.6009, -0.3527,  0.5031, -0.1083]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Size of y:  torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(3, 5)\n",
    "x = Variable(torch.ones((5, 3)))\n",
    "print(x)\n",
    "print(\"Size of x: \", x.size())\n",
    "y = linear(x)\n",
    "print(y)\n",
    "print(\"Size of y: \", y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1059,  0.1676,  0.4489,  0.9154, -0.2483,  0.9295,  0.6973,  0.3895,\n",
      "        -0.3461, -3.2694])\n",
      "tensor([1.1059, 0.1676, 0.4489, 0.9154, 0.0000, 0.9295, 0.6973, 0.3895, 0.0000,\n",
      "        0.0000])\n",
      "tensor([0.1911, 0.0748, 0.0991, 0.1580, 0.0493, 0.1602, 0.1270, 0.0934, 0.0447,\n",
      "        0.0024])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(10))\n",
    "print(x)\n",
    "x_relu = relu(x)\n",
    "print(x_relu)\n",
    "x_softmax = softmax(x, dim=0) # dim选择对哪一维度进行softmax\n",
    "print(x_softmax)\n",
    "print(x_softmax.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 创建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn.functional import log_softmax\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([[-0.1923,  0.5000,  0.1805, -0.9468,  0.0080]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "word2id = {\"hello\": 0, \"world\": 1}\n",
    "vocab_size = len(word2id)\n",
    "embed_dim = 5\n",
    "embedding = nn.Embedding(vocab_size, embed_dim) #即两个单词，单词的词嵌入维度为5\n",
    "hello_id = torch.LongTensor([word2id[\"hello\"]])\n",
    "hello_id = Variable(hello_id)\n",
    "print(hello_id)\n",
    "hello_embed = embedding(hello_id)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['When', 'forty'], 'winters'),\n",
       " (['forty', 'winters'], 'shall'),\n",
       " (['winters', 'shall'], 'besiege'),\n",
       " (['shall', 'besiege'], 'thy'),\n",
       " (['besiege', 'thy'], 'brow,'),\n",
       " (['thy', 'brow,'], 'And'),\n",
       " (['brow,', 'And'], 'dig'),\n",
       " (['And', 'dig'], 'deep'),\n",
       " (['dig', 'deep'], 'trenches'),\n",
       " (['deep', 'trenches'], 'in')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N-Gram Model\n",
    "text_list = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "trigrams = [([text_list[i], text_list[i+1]], text_list[i+2]) for i in range(len(text_list) - 2)]\n",
    "trigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "97\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "vocab = set(text_list)\n",
    "word2id = {word: i for i, word in enumerate(vocab)}\n",
    "id2word = {id : word for word, id in word2id.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(len(vocab))\n",
    "print(len(word2id))\n",
    "print(len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#N-Gram Language model\n",
    "class NGramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, context_size):\n",
    "        super(NGramLanguageModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.linear1 = nn.Linear(embed_dim * context_size, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        :input: (context_size, 1)\n",
    "        '''\n",
    "        embed = self.embedding(input).view(1, -1) # 变成 (1, context_size * embed_dim)\n",
    "        #print(embed)\n",
    "        out = relu(self.linear1(embed)) # (1, 128)\n",
    "        #print(out)\n",
    "        out = relu(self.linear2(out)) # (1, vocab_size)\n",
    "        #print(out.sum())\n",
    "        log_probs = log_softmax(out, dim=-1) # dim=-1取最后一位\n",
    "        #print(log_probs.sum())\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGramLanguageModel(\n",
      "  (embedding): Embedding(97, 10)\n",
      "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=97, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "context_size = 2\n",
    "embed_dim = 10\n",
    "criterion = nn.NLLLoss()\n",
    "model = NGramLanguageModel(vocab_size, embed_dim, context_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([521.8771]), tensor([479.2557]), tensor([443.8206]), tensor([412.8786]), tensor([388.5361]), tensor([373.6031]), tensor([366.6183]), tensor([363.1750]), tensor([361.2988]), tensor([360.1934]), tensor([359.4611]), tensor([358.9449]), tensor([358.5704]), tensor([358.2753]), tensor([358.0569]), tensor([357.8811]), tensor([357.7350]), tensor([357.6149]), tensor([357.5160]), tensor([357.4354])]\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "epochs = 20\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    #print(\"-----------------------------------\")\n",
    "    for context, target in trigrams:\n",
    "        \n",
    "        #model.train()\n",
    "        context_ids = list(map(lambda word : word2id[word], context)) # map(函数, 作用对象)\n",
    "        context_var = Variable(torch.LongTensor(context_ids))\n",
    "        #print(context_var)\n",
    "        # 关于zero_grad(): https://blog.csdn.net/qq_34690929/article/details/79934843\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_probs = model(context_var)\n",
    "        #print(log_probs)\n",
    "        loss = criterion(log_probs.contiguous().view(-1, vocab_size), \n",
    "                         Variable(torch.LongTensor([word2id[target]])).contiguous().view(-1))\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.data\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winters : winters\n",
      "shall : shall\n",
      "besiege : besiege\n",
      "thy : thy\n",
      "brow, : see\n",
      "And : now,\n",
      "dig : dig\n",
      "deep : beauty's\n",
      "trenches : thy\n",
      "in : see\n",
      "thy : thy\n",
      "beauty's : beauty's\n",
      "field, : thou\n",
      "Thy : Thy\n",
      "youth's : so\n",
      "proud : Where\n",
      "livery : so\n",
      "so : so\n",
      "gazed : my\n",
      "on : on\n",
      "now, : now,\n",
      "Will : see\n",
      "be : be\n",
      "a : see\n",
      "totter'd : see\n",
      "weed : see\n",
      "of : of\n",
      "small : my\n",
      "worth : see\n",
      "held: : held:\n",
      "Then : see\n",
      "being : being\n",
      "asked, : deserv'd\n",
      "where : see\n",
      "all : deserv'd\n",
      "thy : thy\n",
      "beauty : beauty\n",
      "lies, : see\n",
      "Where : Where\n",
      "all : shall\n",
      "the : see\n",
      "treasure : see\n",
      "of : of\n",
      "thy : thy\n",
      "lusty : beauty\n",
      "days; : see\n",
      "To : To\n",
      "say, : thy\n",
      "within : see\n",
      "thine : deserv'd\n",
      "own : see\n",
      "deep : see\n",
      "sunken : were\n",
      "eyes, : were\n",
      "Were : see\n",
      "an : winters\n",
      "all-eating : thou\n",
      "shame, : thou\n",
      "and : see\n",
      "thriftless : thou\n",
      "praise. : my\n",
      "How : How\n",
      "much : see\n",
      "more : see\n",
      "praise : my\n",
      "deserv'd : deserv'd\n",
      "thy : thy\n",
      "beauty's : blood\n",
      "use, : thou\n",
      "If : see\n",
      "thou : thou\n",
      "couldst : see\n",
      "answer : were\n",
      "'This : see\n",
      "fair : dig\n",
      "child : see\n",
      "of : of\n",
      "mine : see\n",
      "Shall : see\n",
      "sum : see\n",
      "my : see\n",
      "count, : see\n",
      "and : see\n",
      "make : see\n",
      "my : my\n",
      "old : see\n",
      "excuse,' : see\n",
      "Proving : see\n",
      "his : To\n",
      "beauty : beauty\n",
      "by : see\n",
      "succession : held:\n",
      "thine! : beauty's\n",
      "This : see\n",
      "were : were\n",
      "to : see\n",
      "be : be\n",
      "new : when\n",
      "made : see\n",
      "when : besiege\n",
      "thou : thou\n",
      "art : see\n",
      "old, : see\n",
      "And : see\n",
      "see : see\n",
      "thy : thy\n",
      "blood : blood\n",
      "warm : see\n",
      "when : when\n",
      "thou : thou\n",
      "feel'st : see\n",
      "it : see\n",
      "cold. : be\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "for context, target in trigrams:\n",
    "        model.eval()\n",
    "        context_ids = list(map(lambda word : word2id[word], context)) # map(函数, 作用对象)\n",
    "        context_var = Variable(torch.LongTensor(context_ids))\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_var)\n",
    "        idx = int(torch.argmax(log_probs))\n",
    "        print(\"%s : %s\" %(target, id2word[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
